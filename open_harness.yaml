# Open Harness Configuration

llm:
  # Default provider
  default_provider: "ollama"

  providers:
    ollama:
      base_url: "http://localhost:11434/v1"
      api_key: "ollama"
      api_type: "ollama"  # use native /api/chat (supports think: false)
      extra_params:
        think: false  # disable thinking for faster responses

    lm_studio:
      base_url: "http://192.168.11.3:1234/v1"
      api_key: "lm-studio"

  # Model tiers for routing (small → medium → large)
  # context_length = num_ctx (Ollama KV cache size)
  #   32K  → fits in VRAM → fastest
  #   49K  → VRAM balanced → good for multi-turn
  #   65K  → near VRAM limit → for long orchestration
  models:
    small:
      provider: "ollama"
      model: "qwen3.5:27b"
      max_tokens: 4096
      context_length: 32768
      description: "Fast, simple tasks (32K ctx)"

    medium:
      provider: "ollama"
      model: "qwen3.5:27b"
      max_tokens: 8192
      context_length: 49152
      description: "Balanced performance (48K ctx)"

    large:
      provider: "ollama"
      model: "qwen3.5:27b"
      max_tokens: 16384
      context_length: 65536
      description: "Complex reasoning (64K ctx)"

    # vision:
    #   provider: "lm_studio"
    #   model: "qwen/qwen3-vl-30b"
    #   max_tokens: 8192
    #   description: "Image understanding"

  # Default model tier
  default_tier: "medium"

# Compensation engine settings
compensation:
  max_retries: 3
  retry_strategies:
    - "refine_prompt"
    - "add_examples"
    - "escalate_model"
  parse_fallback: true
  thinking_mode: "never"  # auto, always, never — "never" for qwen3.5 no-think mode

# Tool settings
tools:
  shell:
    timeout: 30
    allowed_commands: []  # empty = all allowed
    blocked_commands: ["rm -rf /", "mkfs", "dd if="]
  file:
    max_read_size: 100000  # bytes

# External agents — task routing for orchestrator mode
# Each agent has built-in defaults for description and strengths.
# Override below to customize routing based on your preferences.
# See docs/external_agents.md for benchmark data and routing recommendations.
external_agents:
  codex:
    enabled: true
    command: "codex"
    # description: "Fast coding and security review"
    # strengths: ["fast_coding", "code_review_security", "ci_cd"]
  gemini:
    enabled: true
    command: "gemini"
    # description: "Large codebase understanding and abstract reasoning"
    # strengths: ["large_codebase", "abstract_reasoning", "science"]
  claude:
    enabled: true
    command: "claude"
    # description: "Complex refactoring, Japanese text, planning"
    # strengths: ["refactoring", "japanese_text", "planning", "code_review_logic"]

# Execution policy — automatic guardrails for autonomous mode
# Modes: safe (strict budgets), balanced (default), full (no limits)
policy:
  mode: "balanced"
  # max_file_writes: 0       # 0 = unlimited
  # max_shell_commands: 0
  # max_git_commits: 10
  # max_external_calls: 5
  # disabled_tools: []
  # denied_paths:             # default blocks /etc, ~/.ssh, .env, etc.
  # writable_paths:           # extra dirs writable beyond project root (globs)
  #   - "/tmp/*"
  #   - "~/other-project/*"

# Memory
memory:
  backend: "sqlite"
  db_path: "~/.open_harness/memory.db"
  max_conversation_turns: 50
